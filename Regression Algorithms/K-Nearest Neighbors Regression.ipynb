{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  K-Nearest Neighbors Regression\n",
    "In this notebook, we will implement k-nearest neighbors regression. We will:\n",
    "  * Find the k-nearest neighbors of a given query input\n",
    "  * Predict the output for the query input using the k-nearest neighbors\n",
    "  * Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in House Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = turicreate.SFrame(r'\\home_data_small.sframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although SFrames offer a number of benefits to users (especially when using Big Data and built-in Turi Create functions), in order to understand the details of the implementation of algorithms it's important to work with a library that allows for direct (and optimized) matrix operations. Numpy is a Python solution to work with matrices (or any multi-dimensional \"array\").\n",
    "\n",
    "Recall that the predicted value given the weights and the features is just the dot product between the feature and weight vector. Similarly, if we put all of the features row-by-row in a matrix then the predicted value for *all* the observations can be computed by right multiplying the \"feature matrix\" by the \"weight vector\". \n",
    " \n",
    "Now we will write a function that will accept an SFrame, a list of feature names and a target feature ('price') and will return two things:\n",
    "* A numpy matrix whose columns are the desired features plus a constant column (this is how we create an intercept)\n",
    "* A numpy array containing the values of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    \n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    \n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe=data_sframe[features]\n",
    "    \n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    \n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray=data_sframe[output]\n",
    "\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need a `normalize_features()` function that normalizes all feature columns to unit norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms=np.linalg.norm(feature_matrix, axis=0)\n",
    "    normalized_features=feature_matrix/norms\n",
    "    \n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_and_validation, test) = sales.random_split(.8, seed=1) # initial train/test split\n",
    "(train, validation) = train_and_validation.random_split(.8, seed=1) # split training set into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all of the numerical inputs listed in `feature_list`, we transform the training, test, and validation SFrames into Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the `sqft_living` feature (typically on the order of thousands) would exert a much larger influence on distance than the `bedrooms` feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train) # normalize training set features (columns)\n",
    "features_test = features_test / norms # normalize test set by training set norms\n",
    "features_valid = features_valid / norms # normalize validation set by training set norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do nearest neighbor regression, we need to compute the distance between our query house and *all* houses in the training set:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(training_matrix, query_house_vector):\n",
    "    distances=np.sqrt(np.sum((training_matrix[0:]-query_house_vector)**2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform K-Nearest Neighbor Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-nearest neighbors, we need to find a *set* of k houses in the training set closest to a given query house. We then make predictions based on these k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_k_nearest_neighbors(k, features_matrix, feature_vector):\n",
    "    distances = compute_distances(features_matrix, feature_vector)\n",
    "    return np.argsort(distances, axis = 0)[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, we write a function that predicts the value of a given query house. **For simplicity, we take the average of the prices of the k nearest neighbors in the training set**. The function has the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature vector of the query house, whose price we are predicting.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_k_avg(k, features_matrix, output_values, feature_vector):\n",
    "    k_neigbors = compute_k_nearest_neighbors(k, features_matrix, feature_vector)\n",
    "    avg_value = np.mean(output_values[k_neigbors])\n",
    "    return avg_value  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function to predict the value of *each and every* house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function will take the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature matrix for the query set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_k_all(k, features_matrix, output_values, feature_vector):\n",
    "    num_of_rows = feature_vector.shape[0]\n",
    "    predicted_values = []\n",
    "    for i in xrange(num_of_rows):\n",
    "        avg_value = compute_distances_k_avg(k, features_train, output_train, features_test[i])\n",
    "        predicted_values.append(avg_value)\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k that produced the lowest RSS on validation set: k = 15\n",
      "RSS: 240936866247228.218750\n"
     ]
    }
   ],
   "source": [
    "# choose the best k\n",
    "rss_all = []\n",
    "for k in range(1,16):    \n",
    "    predict_value = compute_distances_k_all(k, features_train, output_train, features_valid)\n",
    "    residual = (output_valid - predict_value)\n",
    "    rss = sum(residual**2)\n",
    "    rss_all.append(rss)\n",
    "\n",
    "for i,val in enumerate(rss_all):\n",
    "    #print(i)\n",
    "    if val == min(rss_all):        \n",
    "        print(\"k that produced the lowest RSS on validation set: k = {}\".format(i+1))\n",
    "        print(\"RSS: %f\" %val)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the performance as a function of `k`,  we plot the RSS on the VALIDATION set for each considered `k` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f73b75902d0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 16)\n",
    "plt.plot(kvals, rss_all,'bo-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot illustrates the increasing performance of the algorithm as the number of included neighbors increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
